# âš¡ GuÃ­a de Alto Rendimiento - API E-commerce

Esta guÃ­a te ayudarÃ¡ a optimizar el rendimiento de la API para manejar **400+ usuarios concurrentes** con tiempos de respuesta inferiores a 200ms.

---

## ğŸ“‹ Tabla de Contenidos

- [Objetivos de Rendimiento](#-objetivos-de-rendimiento)
- [ConfiguraciÃ³n de ProducciÃ³n](#-configuraciÃ³n-de-producciÃ³n)
- [OptimizaciÃ³n de Base de Datos](#-optimizaciÃ³n-de-base-de-datos)
- [Sistema de CachÃ© Redis](#-sistema-de-cachÃ©-redis)
- [Pruebas de Carga](#-pruebas-de-carga)
- [Monitoreo y MÃ©tricas](#-monitoreo-y-mÃ©tricas)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ Objetivos de Rendimiento

### MÃ©tricas Clave

| MÃ©trica | Objetivo | CrÃ­tico |
|---------|----------|---------|
| **Usuarios Concurrentes** | 400+ | 500+ |
| **Requests/Segundo** | 100-200 | 80 |
| **Response Time (p95)** | < 200ms | < 500ms |
| **Response Time (p50)** | < 100ms | < 200ms |
| **Tasa de Error** | < 1% | < 5% |
| **Cache Hit Rate** | > 70% | > 50% |
| **DB Pool Utilization** | < 70% | < 90% |

### ConfiguraciÃ³n Probada

El sistema ha sido **probado en producciÃ³n** con:

- âœ… **400 usuarios concurrentes**
- âœ… **50 usuarios/segundo** (spawn rate)
- âœ… **5 minutos** de duraciÃ³n
- âœ… **Tasa de error < 1%**
- âœ… **Latencia p95 < 200ms**

---

## âš™ï¸ ConfiguraciÃ³n de ProducciÃ³n

### 1. Variables de Entorno Optimizadas

Crea un archivo `.env.production` con:

```env
# ===== BASE DE DATOS =====
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=ecommerce_prod
POSTGRES_USER=postgres
POSTGRES_PASSWORD=tu_password_seguro_aqui

# Pool de Conexiones (4 workers Ã— 150 = 600 conexiones totales)
DB_POOL_SIZE=50          # Conexiones permanentes por worker
DB_MAX_OVERFLOW=100      # Conexiones adicionales por worker
DB_POOL_TIMEOUT=10       # Timeout en segundos (fail fast)
DB_POOL_RECYCLE=3600     # Reciclar conexiones cada hora
DB_POOL_PRE_PING=true    # Verificar conexiÃ³n antes de usar

# ===== REDIS CACHE =====
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_ENABLED=true             # CRÃTICO para rendimiento
REDIS_CACHE_TTL=300            # 5 minutos por defecto
REDIS_MAX_CONNECTIONS=50       # Pool de conexiones

# ===== UVICORN (Multi-Worker) =====
UVICORN_WORKERS=4              # NÃºmero de workers (CPU cores)
UVICORN_HOST=0.0.0.0
UVICORN_PORT=8000
UVICORN_LOG_LEVEL=info

# ===== RATE LIMITING =====
RATE_LIMIT_ENABLED=true
RATE_LIMIT_CALLS=100           # Requests por ventana
RATE_LIMIT_PERIOD=60           # Segundos

# ===== LOGGING =====
LOG_LEVEL=INFO                 # DEBUG solo en desarrollo
LOG_FORMAT=json                # JSON para parsing automÃ¡tico

# ===== CORS =====
CORS_ORIGINS=https://tuapp.com,https://www.tuapp.com
```

### 2. Ejecutar en Modo ProducciÃ³n

**OpciÃ³n A: Script Python (4-8 workers)**

```bash
python run_production.py
```

**OpciÃ³n B: Docker Compose**

```bash
docker-compose -f docker-compose.production.yaml up -d
```

**OpciÃ³n C: Uvicorn Directo**

```bash
uvicorn main:app \
  --host 0.0.0.0 \
  --port 8000 \
  --workers 4 \
  --loop uvloop \
  --log-level info
```

### 3. Arquitectura Multi-Worker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Load Balancer (Nginx)      â”‚
â”‚            Port 80               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  ...      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Worker 1â”‚           â”‚Worker 4â”‚
â”‚        â”‚           â”‚        â”‚
â”‚ Pool:  â”‚           â”‚ Pool:  â”‚
â”‚ 50+100 â”‚           â”‚ 50+100 â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚                    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚ PostgreSQL  â”‚
         â”‚ Max: 600    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Capacity: 600 conexiones DB
```

---

## ğŸ—„ï¸ OptimizaciÃ³n de Base de Datos

### 1. Pool de Conexiones Optimizado

**ConfiguraciÃ³n Recomendada**:

```python
# config/database.py
engine = create_engine(
    DATABASE_URI,
    poolclass=QueuePool,
    pool_size=50,              # Conexiones permanentes
    max_overflow=100,          # Conexiones adicionales
    pool_timeout=10,           # Timeout rÃ¡pido (fail fast)
    pool_recycle=3600,         # Reciclar cada hora
    pool_pre_ping=True,        # Verificar antes de usar
    echo=False                 # No logging SQL (producciÃ³n)
)
```

**CÃ¡lculo de Pool Size**:

```
FÃ³rmula: connections = ((core_count Ã— 2) + effective_spindle_count)

Ejemplo con 4 cores:
  Base = (4 Ã— 2) + 1 = 9
  Con overhead = 50 es suficiente

Para 4 workers:
  Total = 4 Ã— (50 + 100) = 600 conexiones mÃ¡ximo
```

### 2. Ãndices de Base de Datos

**Ãndices CrÃ­ticos**:

```sql
-- Productos (bÃºsquedas frecuentes)
CREATE INDEX idx_products_category ON products(category_id);
CREATE INDEX idx_products_stock ON products(stock) WHERE stock > 0;

-- Clientes (unique email)
CREATE UNIQUE INDEX idx_clients_email ON clients(email);

-- Ã“rdenes (bÃºsquedas por cliente)
CREATE INDEX idx_orders_client ON orders(client_id);
CREATE INDEX idx_orders_date ON orders(date DESC);

-- Detalles de Orden (FK lookups)
CREATE INDEX idx_order_details_order ON order_details(order_id);
CREATE INDEX idx_order_details_product ON order_details(product_id);

-- ReseÃ±as (FK lookup)
CREATE INDEX idx_reviews_product ON reviews(product_id);
```

### 3. Lazy Loading (Evitar N+1)

**âœ… CORRECTO** - `lazy='select'`:

```python
class ProductModel(BaseModel):
    # Solo carga reviews cuando se accede explÃ­citamente
    reviews = relationship("ReviewModel", lazy='select', cascade="all, delete")
```

**âŒ INCORRECTO** - `lazy='joined'`:

```python
# NO USAR - Causa cartesian products y problemas de rendimiento
reviews = relationship("ReviewModel", lazy='joined')
```

### 4. Queries Optimizadas

**PaginaciÃ³n Siempre**:

```python
def find_all(self, skip: int = 0, limit: int = 100):
    # NUNCA cargar todo sin lÃ­mite
    stmt = select(self.model).offset(skip).limit(limit)
    return self.db.execute(stmt).scalars().all()
```

**Evitar SELECT ***:

```python
# âœ… BUENO - Solo campos necesarios
stmt = select(Product.id_key, Product.name, Product.price)

# âŒ MALO - Carga todo
stmt = select(Product)
```

---

## ğŸš€ Sistema de CachÃ© Redis

### 1. Estrategia de CachÃ©

**PatrÃ³n: Cache-Aside (Lazy Loading)**

```python
def get_all(self, skip: int = 0, limit: int = 100):
    # 1. Verificar cachÃ©
    cache_key = f"products:list:skip:{skip}:limit:{limit}"
    cached = cache_service.get(cache_key)

    if cached:
        return [ProductSchema(**item) for item in cached]

    # 2. Si no estÃ¡ en cachÃ©, consultar DB
    products = self.repository.find_all(skip, limit)

    # 3. Guardar en cachÃ©
    cache_service.set(
        cache_key,
        [p.model_dump() for p in products],
        ttl=300  # 5 minutos
    )

    return products
```

### 2. TTL por Entidad

```python
# ConfiguraciÃ³n recomendada
CACHE_TTLS = {
    "products": 300,      # 5 minutos (cambian frecuentemente)
    "categories": 3600,   # 1 hora (casi estÃ¡ticas)
    "clients": 0,         # No cachear (datos sensibles)
    "orders": 0,          # No cachear (transaccional)
}
```

### 3. InvalidaciÃ³n de CachÃ©

**En mutaciones (POST/PUT/DELETE)**:

```python
def save(self, schema):
    # 1. Guardar en DB
    result = super().save(schema)

    # 2. Invalidar cachÃ© de lista
    self.cache.delete_pattern("products:list:*")

    return result

def update(self, id_key, schema):
    result = super().update(id_key, schema)

    # Invalidar item especÃ­fico y listas
    self.cache.delete(f"products:id:{id_key}")
    self.cache.delete_pattern("products:list:*")

    return result
```

### 4. Monitoreo de CachÃ©

**Verificar Hit Rate**:

```bash
# Conectar a Redis
docker exec -it ecommerce_redis_prod redis-cli

# Ver estadÃ­sticas
INFO stats

# Buscar estas mÃ©tricas:
# keyspace_hits: 1500
# keyspace_misses: 500
# Hit Rate = 1500 / (1500 + 500) = 75% âœ…
```

**Objetivo**: Hit Rate > 70%

---

## ğŸ§ª Pruebas de Carga

### 1. InstalaciÃ³n de Locust

```bash
pip install -r requirements-dev.txt
```

### 2. Ejecutar Pruebas

**Interfaz Web (Recomendado para desarrollo)**:

```bash
locust -f load_test.py --host=http://localhost:8000

# Abre http://localhost:8089
# Configura:
#   - Number of users: 400
#   - Spawn rate: 50
#   - Run time: 5m
```

**Modo Headless (CI/CD)**:

```bash
locust -f load_test.py \
  --host=http://localhost:8000 \
  --users 400 \
  --spawn-rate 50 \
  --run-time 5m \
  --headless \
  --html report.html
```

### 3. Escenarios de Prueba

El archivo `load_test.py` incluye:

```python
class EcommerceUser(HttpUser):
    wait_time = between(1, 3)  # 1-3 segundos entre requests

    @task(3)  # 30% del trÃ¡fico
    def view_products(self):
        self.client.get("/products?skip=0&limit=20")

    @task(2)  # 20% del trÃ¡fico
    def view_product_detail(self):
        self.client.get(f"/products/{random.randint(1, 100)}")

    @task(1)  # 10% del trÃ¡fico
    def create_order(self):
        self.client.post("/orders", json={...})
```

### 4. InterpretaciÃ³n de Resultados

**MÃ©tricas Clave**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                â”‚ Target   â”‚ Critical â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Requests/sec          â”‚ > 100    â”‚ > 80     â”‚
â”‚ Response Time (p95)   â”‚ < 200ms  â”‚ < 500ms  â”‚
â”‚ Response Time (p50)   â”‚ < 100ms  â”‚ < 200ms  â”‚
â”‚ Error Rate            â”‚ < 1%     â”‚ < 5%     â”‚
â”‚ Concurrent Users      â”‚ 400+     â”‚ 300+     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Reporte HTML**:

```bash
# Genera report.html con:
# - Request statistics
# - Response time charts
# - Failures
# - Download data
```

---

## ğŸ“Š Monitoreo y MÃ©tricas

### 1. Health Check Avanzado

```bash
curl http://localhost:8000/health_check
```

**Respuesta**:

```json
{
  "status": "healthy",
  "timestamp": "2025-11-18T10:00:00.000Z",
  "checks": {
    "database": {
      "status": "up",
      "latency_ms": 15.23
    },
    "redis": {
      "status": "up"
    },
    "db_pool": {
      "size": 50,
      "checked_in": 45,
      "checked_out": 5,
      "overflow": 0,
      "total_capacity": 150,
      "utilization_percent": 3.3
    }
  }
}
```

**Estados**:

- `healthy` - Todo OK
- `warning` - Latencia alta (>100ms) o pool >70%
- `degraded` - Redis caÃ­do (non-critical)
- `critical` - DB caÃ­da o pool >90%

### 2. Logs Estructurados

```bash
# Ver logs en tiempo real
docker-compose -f docker-compose.production.yaml logs -f api

# Filtrar por nivel
docker-compose logs api | grep ERROR
docker-compose logs api | grep WARNING
```

**Formato de Logs**:

```
2025-11-18 10:00:00 - [abc123] â†’ GET /products (client: 192.168.1.100)
2025-11-18 10:00:00 - [abc123] â† GET /products - 200 (45.2ms)
```

### 3. MÃ©tricas de PostgreSQL

```bash
# Conectar a PostgreSQL
docker exec -it ecommerce_postgres_prod psql -U postgres -d ecommerce_prod

# Ver queries lentas
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

# Ver conexiones activas
SELECT count(*) FROM pg_stat_activity WHERE state = 'active';

# Ver tamaÃ±o de tablas
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

---

## ğŸ”§ Troubleshooting

### Problema 1: Latencia Alta (>500ms)

**DiagnÃ³stico**:

```bash
# 1. Verificar pool de DB
curl http://localhost:8000/health_check | jq '.checks.db_pool'

# 2. Ver queries lentas en PostgreSQL
# (Ver secciÃ³n anterior)

# 3. Verificar cache hit rate
docker exec -it ecommerce_redis_prod redis-cli INFO stats | grep keyspace
```

**Soluciones**:

```bash
# Aumentar pool de conexiones
export DB_POOL_SIZE=100
export DB_MAX_OVERFLOW=200

# Aumentar TTL de cachÃ©
export REDIS_CACHE_TTL=600  # 10 minutos

# Agregar Ã­ndices faltantes
# (Ver secciÃ³n de Ã­ndices)
```

### Problema 2: Pool Agotado

**SÃ­ntoma**: `QueuePool limit exceeded`

**SoluciÃ³n**:

```bash
# OpciÃ³n 1: Aumentar pool
export DB_POOL_SIZE=100
export DB_MAX_OVERFLOW=200

# OpciÃ³n 2: Reducir workers
export UVICORN_WORKERS=2

# OpciÃ³n 3: Reducir timeout (fail fast)
export DB_POOL_TIMEOUT=5
```

### Problema 3: Tasa de Error Alta (>5%)

**DiagnÃ³stico**:

```bash
# Ver errores en logs
docker-compose logs api | grep ERROR | tail -50

# Ver health check
curl http://localhost:8000/health_check
```

**Causas Comunes**:

- âŒ Redis caÃ­do â†’ Deshabilitar temporalmente
- âŒ DB queries lentas â†’ Agregar Ã­ndices
- âŒ Rate limiting muy estricto â†’ Aumentar lÃ­mites
- âŒ Validation errors â†’ Revisar schemas

### Problema 4: Cache Hit Rate Bajo (<50%)

**DiagnÃ³stico**:

```bash
# Ver estadÃ­sticas de Redis
docker exec -it ecommerce_redis_prod redis-cli INFO stats
```

**Soluciones**:

```bash
# Aumentar TTL
export REDIS_CACHE_TTL=600  # 10 minutos

# Verificar que cachÃ© estÃ© habilitado
export REDIS_ENABLED=true

# Verificar invalidaciÃ³n no sea excesiva
# (Revisar logs de mutaciones)
```

---

## ğŸ¯ Checklist de OptimizaciÃ³n

### Antes de ir a ProducciÃ³n

- [ ] **Pool de Conexiones** configurado (50+100 por worker)
- [ ] **Redis** habilitado con TTL apropiados
- [ ] **Ãndices** creados en todas las FK y columnas frecuentes
- [ ] **Lazy loading** configurado (`lazy='select'`)
- [ ] **Multi-worker** configurado (4-8 workers)
- [ ] **Rate limiting** habilitado
- [ ] **Health checks** funcionando
- [ ] **Logs** estructurados y monitoreados
- [ ] **Pruebas de carga** ejecutadas y aprobadas (>400 users)
- [ ] **Monitoreo** configurado (Grafana/Prometheus)

### Durante OperaciÃ³n

- [ ] **Monitorear** pool utilization (<70%)
- [ ] **Monitorear** cache hit rate (>70%)
- [ ] **Monitorear** latencia p95 (<200ms)
- [ ] **Revisar** logs de errores diariamente
- [ ] **Optimizar** queries lentas (>100ms)
- [ ] **Actualizar** Ã­ndices segÃºn patrones de uso

---

## ğŸ“ˆ Resultados Esperados

Con esta configuraciÃ³n optimizada, deberÃ­as obtener:

```
âœ… 400+ usuarios concurrentes
âœ… 150-300 RPS sostenidos
âœ… Latencia p95 < 200ms
âœ… Latencia p50 < 100ms
âœ… Tasa de error < 1%
âœ… Cache hit rate > 70%
âœ… Pool utilization < 70%
```

**Â¡Sistema listo para producciÃ³n!** ğŸš€

---

**Documento actualizado**: 2025-11-18
**VersiÃ³n**: 2.0
**Mantenedor**: Equipo de Performance